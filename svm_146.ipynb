{"metadata":{"anaconda-cloud":{},"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","nbconvert_exporter":"python","file_extension":".py","pygments_lexer":"ipython3","version":"3.6.3","codemirror_mode":{"name":"ipython","version":3},"mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Importing librairies\n\nimport pandas as pd \nimport numpy as np\n\n# Scikit-learn library: For SVM\nfrom sklearn import preprocessing\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import svm\n\nimport itertools\n\n# Matplotlib library to plot the charts\nimport matplotlib.pyplot as plt\nimport matplotlib.mlab as mlab\n\n# Library for the statistic data vizualisation\nimport seaborn\n\n%matplotlib inline\n\n","metadata":{"_cell_guid":"95f30dd3-7b08-4087-b156-5bf3250ce742","_uuid":"dc31e50ac68836610ff16246bbda63d7ae6db49b","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/creditcard.csv') # Reading the file .csv\ndf = pd.DataFrame(data) # Converting data to Panda DataFrame","metadata":{"_cell_guid":"b3cd20ab-f13e-4083-9c36-9291414694c2","_uuid":"232bc475856a4f5e92083e1757242020100ee284","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(data) # Converting data to Panda DataFrame","metadata":{"_cell_guid":"baeaea24-4736-473a-a85c-cbc3ddde9ed3","_uuid":"9d450721809ddf6aa0754b705062bfdf837d9c54","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df.describe() # Description of statistic features (Sum, Average, Variance, minimum, 1st quartile, 2nd quartile, 3rd Quartile and Maximum)","metadata":{"_cell_guid":"6aade7ce-2b87-4cd0-a998-3a54ac14d4df","_uuid":"4eafc2bb6228637b51ba4e1c97ded7456440cd0f"},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df_fraud = df[df['Class'] == 1] # Recovery of fraud data\nplt.figure(figsize=(15,10))\nplt.scatter(df_fraud['Time'], df_fraud['Amount']) # Display fraud amounts according to their time\nplt.title('Scratter plot amount fraud')\nplt.xlabel('Time')\nplt.ylabel('Amount')\nplt.xlim([0,175000])\nplt.ylim([0,2500])\nplt.show()","metadata":{"_cell_guid":"aaf455b3-f3a1-4316-99c6-cbd4c0a8b33d","_uuid":"346c8874f9118fcbcea8f028804179eed54eca69"},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"nb_big_fraud = df_fraud[df_fraud['Amount'] > 1000].shape[0] # Recovery of frauds over 1000\nprint('There are only '+ str(nb_big_fraud) + ' frauds where the amount was bigger than 1000 over ' + str(df_fraud.shape[0]) + ' frauds')","metadata":{"_cell_guid":"8b77e909-ab26-4783-8005-bf591d66cf5b","_uuid":"9a273b886643735328b0666edf70d12807804fe1"},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"number_fraud = len(data[data.Class == 1])\nnumber_no_fraud = len(data[data.Class == 0])\nprint('There are only '+ str(number_fraud) + ' frauds in the original dataset, even though there are ' + str(number_no_fraud) +' no frauds in the dataset.')","metadata":{"_cell_guid":"02332e68-9fec-48c5-89cd-06ce360f2e9c","_uuid":"bd071ed3ed6dcf625adc45196f615d62cd462ab1"},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"print(\"The accuracy of the classifier then would be : \"+ str((284315-492)/284315)+ \" which is the number of good classification over the number of tuple to classify\")","metadata":{"_cell_guid":"32763345-e2ac-455b-9265-50bcc304da07","_uuid":"5139011572ad26820d148f408fb3d839899331b5"},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df_corr = df.corr() # Calculation of the correlation coefficients in pairs, with the default method:\n                    # Pearson, Standard Correlation Coefficient","metadata":{"_cell_guid":"a575fa45-aa54-42d8-bc41-7901109b0a30","_uuid":"c79fd2aee5021d4f09523411513e43220bede053","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\nseaborn.heatmap(df_corr, cmap=\"YlGnBu\") # Displaying the Heatmap\nseaborn.set(font_scale=2,style='white')\n\nplt.title('Heatmap correlation')\nplt.show()","metadata":{"_cell_guid":"f3fbb40b-c628-45bc-96df-599c83ea1a7f","_uuid":"238eb36a153c7049fef3fd5f4f07f363b4aa92b9"},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"rank = df_corr['Class'] # Retrieving the correlation coefficients per feature in relation to the feature class\ndf_rank = pd.DataFrame(rank) \ndf_rank = np.abs(df_rank).sort_values(by='Class',ascending=False) # Ranking the absolute values of the coefficients\n                                                                  # in descending order\ndf_rank.dropna(inplace=True) # Removing Missing Data (not a number)","metadata":{"_cell_guid":"513071fd-e5e9-4ad5-a45a-bfcfa9376cdc","_uuid":"f5b17abf4e8a26f4f63f4379b1d0b2822b5a3c85","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# We seperate ours data in two groups : a train dataset and a test dataset\n\n# First we build our train dataset\ndf_train_all = df[0:150000] # We cut in two the original dataset\ndf_train_1 = df_train_all[df_train_all['Class'] == 1] # We seperate the data which are the frauds and the no frauds\ndf_train_0 = df_train_all[df_train_all['Class'] == 0]\nprint('In this dataset, we have ' + str(len(df_train_1)) +\" frauds so we need to take a similar number of non-fraud\")\n\ndf_sample=df_train_0.sample(300)\ndf_train = df_train_1.append(df_sample) # We gather the frauds with the no frauds. \ndf_train = df_train.sample(frac=1) # Then we mix our dataset","metadata":{"_cell_guid":"679f5dd1-5665-4de2-942b-6ac95ff1a02f","_uuid":"d5b23951407345e6a89ca312967e582c66e11af3"},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"X_train = df_train.drop(['Time', 'Class'],axis=1) # We drop the features Time (useless), and the Class (label)\ny_train = df_train['Class'] # We create our label\nX_train = np.asarray(X_train)\ny_train = np.asarray(y_train)","metadata":{"_cell_guid":"36f77663-2b2a-412f-a759-0fd3a0bf06ab","_uuid":"d9707da7dc04b2a415608f2833dd5d732dd98925","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"############################## with all the test dataset to see if the model learn correctly ##################\ndf_test_all = df[150000:]\n\nX_test_all = df_test_all.drop(['Time', 'Class'],axis=1)\ny_test_all = df_test_all['Class']\nX_test_all = np.asarray(X_test_all)\ny_test_all = np.asarray(y_test_all)","metadata":{"_cell_guid":"d7c350a4-6874-46b8-b699-4c27aa42dade","_uuid":"975a023dc24a60832b3a670aecf2dbe3b9390183","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"X_train_rank = df_train[df_rank.index[1:11]] # We take the first ten ranked features\nX_train_rank = np.asarray(X_train_rank)","metadata":{"_cell_guid":"d7246290-1ada-4be9-87a3-833620d23e04","_uuid":"274f5e99f592cdc487e39eb60419a17a1cada5fe","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"############################## with all the test dataset to see if the model learn correctly ##################\nX_test_all_rank = df_test_all[df_rank.index[1:11]]\nX_test_all_rank = np.asarray(X_test_all_rank)\ny_test_all = np.asarray(y_test_all)","metadata":{"_cell_guid":"1c9addbe-d94c-44e8-84a9-1afdd13291be","_uuid":"7a28465f8d7a4577ca6f4d1eb1f372a87da87c63","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class_names=np.array(['0','1']) # Binary label, Class = 1 (fraud) and Class = 0 (no fraud)","metadata":{"_cell_guid":"e298b2fd-6569-4e38-97b1-227a0960e4fe","_uuid":"55d1987b1b3963fb9ca5fd1142faae095dfa338b","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Function to plot the confusion Matrix\ndef plot_confusion_matrix(cm, classes,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = 'd' \n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","metadata":{"_cell_guid":"c57ed880-9e78-4620-9158-bfe626bf75f6","_uuid":"a484397df965faf0e489e17a7e0b0ccf36c8bf84","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"classifier = svm.SVC(kernel='linear') # We set a SVM classifier, the default SVM Classifier (Kernel = Radial Basis Function)","metadata":{"_cell_guid":"1402594d-a2bf-4bef-a4b1-ffbada37e8b6","_uuid":"54b464be3bacc3a8730ef22a44de83979a541952","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"classifier.fit(X_train, y_train) # Then we train our model, with our balanced data train.","metadata":{"_cell_guid":"671a5ed5-1103-4dd7-b7ef-f4959320b9b8","_uuid":"ae95b7f9abb4c55f97a7b0e844966d766acd14e1"},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"prediction_SVM_all = classifier.predict(X_test_all) #And finally, we predict our data test.","metadata":{"_cell_guid":"b7f42a0d-5dc2-482e-83dd-95be0b709fae","_uuid":"06c4a00a2aeb9989135ef954ade5bf1dd750f8ce","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(y_test_all, prediction_SVM_all)\nplot_confusion_matrix(cm,class_names)","metadata":{"_cell_guid":"5558cbc6-e22c-4748-8640-35cd43358d1c","_uuid":"cf58f6438e736b63903773caf38cd364a73178d4"},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"print('Our criterion give a result of ' \n      + str( ( (cm[0][0]+cm[1][1]) / (sum(cm[0]) + sum(cm[1])) + 4 * cm[1][1]/(cm[1][0]+cm[1][1])) / 5))","metadata":{"_cell_guid":"21cde17a-738a-4c75-a6b3-16b4c055188b","_uuid":"7000a8cec37987f50f8e398e48894c5ece0a7470"},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"print('We have detected ' + str(cm[1][1]) + ' frauds / ' + str(cm[1][1]+cm[1][0]) + ' total frauds.')\nprint('\\nSo, the probability to detect a fraud is ' + str(cm[1][1]/(cm[1][1]+cm[1][0])))\nprint(\"the accuracy is : \"+str((cm[0][0]+cm[1][1]) / (sum(cm[0]) + sum(cm[1]))))","metadata":{"_cell_guid":"08447323-4ed7-4e29-a3c1-c86682ff63f0","_uuid":"7c7bb0d2cfffdbdbe10df915a429c88e36a60957"},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"classifier.fit(X_train_rank, y_train) # Then we train our model, with our balanced data train.\nprediction_SVM = classifier.predict(X_test_all_rank) #And finally, we predict our data test.","metadata":{"_cell_guid":"5e73fef0-c4d4-450b-9961-e841767e0342","_uuid":"b4247cb1dd4d7af91421d01f7067898799fdbfd8","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(y_test_all, prediction_SVM)\nplot_confusion_matrix(cm,class_names)","metadata":{"_cell_guid":"e84710c9-59fe-4205-8c05-e989d5942712","_uuid":"bb4defbee6e8ebaff98eebaff7701503d2b65434"},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"print('Our criterion give a result of ' \n      + str( ( (cm[0][0]+cm[1][1]) / (sum(cm[0]) + sum(cm[1])) + 4 * cm[1][1]/(cm[1][0]+cm[1][1])) / 5))","metadata":{"_cell_guid":"d310bf29-6673-4882-8387-e4b6fb53ee86","_uuid":"a0d4e792c37722f84d9b55432b286bfcafec1293"},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"print('We have detected ' + str(cm[1][1]) + ' frauds / ' + str(cm[1][1]+cm[1][0]) + ' total frauds.')\nprint('\\nSo, the probability to detect a fraud is ' + str(cm[1][1]/(cm[1][1]+cm[1][0])))\nprint(\"the accuracy is : \"+str((cm[0][0]+cm[1][1]) / (sum(cm[0]) + sum(cm[1]))))","metadata":{"_cell_guid":"9fb3cb24-8f70-423c-89c7-aa91d15172ad","_uuid":"f39c12ef5d8c91185b1873483fd93e26c13c3cab"},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"classifier_b = svm.SVC(kernel='linear',class_weight={0:0.60, 1:0.40})","metadata":{"_cell_guid":"33f60bc0-38c6-4ee7-a348-e2254bca727c","_uuid":"5c36459b8b55ab20a57097d820f7f24a856c20f7","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"classifier_b.fit(X_train, y_train) # Then we train our model, with our balanced data train.","metadata":{"_cell_guid":"07b6b2e3-4cd2-4202-b2a9-3d22edadf650","_uuid":"4b29ebf3f9fd2e591498e747d453297ccc9d95f0"},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"prediction_SVM_b_all = classifier_b.predict(X_test_all) #We predict all the data set.","metadata":{"_cell_guid":"63406a9e-e7f7-4bbe-9945-55daf2c384a8","_uuid":"c2b29f36198561711dd23cdef243bd7d9b41bce7","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(y_test_all, prediction_SVM_b_all)\nplot_confusion_matrix(cm,class_names)","metadata":{"_cell_guid":"42f417eb-5c5c-4d1d-af59-349d17d77f6f","_uuid":"e462d0526a115a87d27f8a1c24bbb6fd3b9e9eeb"},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"print('Our criterion give a result of ' \n      + str( ( (cm[0][0]+cm[1][1]) / (sum(cm[0]) + sum(cm[1])) + 4 * cm[1][1]/(cm[1][0]+cm[1][1])) / 5))","metadata":{"_cell_guid":"9aa0594f-88da-4015-a712-c4e378d276c9","_uuid":"5f80761a24cf70ac29bbf3650a7db0ae6c273600"},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"print('We have detected ' + str(cm[1][1]) + ' frauds / ' + str(cm[1][1]+cm[1][0]) + ' total frauds.')\nprint('\\nSo, the probability to detect a fraud is ' + str(cm[1][1]/(cm[1][1]+cm[1][0])))\nprint(\"the accuracy is : \"+str((cm[0][0]+cm[1][1]) / (sum(cm[0]) + sum(cm[1]))))","metadata":{"_cell_guid":"d03a28ad-b9e1-4c2c-bed2-06308b1816cf","_uuid":"3d674db8f4eeb8ed4a8583e3d5cd40f8561ae33d"},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"classifier_b.fit(X_train_rank, y_train) # Then we train our model, with our balanced data train.\nprediction_SVM = classifier_b.predict(X_test_all_rank) #And finally, we predict our data test.","metadata":{"_cell_guid":"ef932b2b-72bf-47df-9157-ae3249665467","_uuid":"9d241abdaded4809eafe7e2c885150e63f4ae4d0","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(y_test_all, prediction_SVM)\nplot_confusion_matrix(cm,class_names)","metadata":{"_cell_guid":"a9ce5f16-08b3-4932-89ee-1ed934684482","_uuid":"3e6542b40144dbef93f27144198299e9b7a84bbe"},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"print('Our criterion give a result of ' \n      + str( ( (cm[0][0]+cm[1][1]) / (sum(cm[0]) + sum(cm[1])) + 4 * cm[1][1]/(cm[1][0]+cm[1][1])) / 5))","metadata":{"_cell_guid":"ff879d9e-b9c3-40b7-a9a6-dae5ce11a88e","_uuid":"653485d7a5c7feb2052321b7a05b4415b63fdac8"},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"print('We have detected ' + str(cm[1][1]) + ' frauds / ' + str(cm[1][1]+cm[1][0]) + ' total frauds.')\nprint('\\nSo, the probability to detect a fraud is ' + str(cm[1][1]/(cm[1][1]+cm[1][0])))\nprint(\"the accuracy is : \"+str((cm[0][0]+cm[1][1]) / (sum(cm[0]) + sum(cm[1]))))","metadata":{"_cell_guid":"6aa458bb-3314-492b-b9c3-4d811c5a2db5","_uuid":"725c2ff781e0a1c86eb160eeab0da9723aee91cc"},"execution_count":38,"outputs":[]}]}