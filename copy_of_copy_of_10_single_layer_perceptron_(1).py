# -*- coding: utf-8 -*-
"""Copy of Copy of 10 single layer perceptron (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z4IR42o4mk4CSZ7_R7jE-X0xdNC-LwyD
"""



import numpy as np

def step_function(x):
    if x >= 0:
        return 1
    else:
        return 0

def logical_NOT(x):
    w = np.array([-1]) 
    b = 0
    x = np.array(x) 
    z = np.dot(w, x) + b 
    y = step_function(z)
    return y

def logical_NAND(x):
    w = np.array([-1, -1]) 
    b = 2 
    x = np.array(x) 
    z = np.dot(w, x) + b 
    y = step_function(z) 
    return y

def logical_NOR(x):
    w = np.array([-1, -1])
    b = 0 
    x = np.array(x) 
    z = np.dot(w, x) + b
    y = step_function(z) 
    return y

print(logical_NOT(0))

print(logical_NOT(1))

print(logical_NAND([0, 0])) 
print(logical_NAND([0, 1])) 
print(logical_NAND([1, 0])) 
print(logical_NAND([1, 1]))

print(logical_NOR([0, 0])) 
print(logical_NOR([0, 1])) 
print(logical_NOR([1, 0])) 
print(logical_NOR([1, 1]))

